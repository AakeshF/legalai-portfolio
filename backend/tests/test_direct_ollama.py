import asyncio
import httpx
from services.ollama_service import OllamaService

async def test_ollama():
    """Test Ollama directly"""
    try:
        # Initialize Ollama service
        ollama = OllamaService()
        print(f"‚úÖ Ollama initialized with model: {ollama.model}")
        print(f"   Base URL: {ollama.base_url}")
        
        # Test generation using the correct method
        print("\nüîÑ Testing Ollama generation...")
        response = await ollama.process_chat_message(
            message="Hello, can you help me with legal documents?",
            documents=[],
            chat_history=[]
        )
        print(f"\nü§ñ Ollama Response: {response['answer'][:200]}...")
        print(f"   Response Type: {response.get('response_metrics', {}).get('response_type', 'unknown')}")
        
        return True
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return False

if __name__ == "__main__":
    asyncio.run(test_ollama())
